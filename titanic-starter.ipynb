{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "destroyed-arkansas",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-04-27T04:59:14.544987Z",
     "iopub.status.busy": "2021-04-27T04:59:14.544320Z",
     "iopub.status.idle": "2021-04-27T04:59:16.071140Z",
     "shell.execute_reply": "2021-04-27T04:59:16.070448Z"
    },
    "papermill": {
     "duration": 1.540541,
     "end_time": "2021-04-27T04:59:16.071313",
     "exception": false,
     "start_time": "2021-04-27T04:59:14.530772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "from math import log\n",
    "from statistics import stdev\n",
    "\n",
    "import os, sys\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# For print supression\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "        \n",
    "# Turn off warning messages\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "noted-evaluation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T04:59:16.108391Z",
     "iopub.status.busy": "2021-04-27T04:59:16.107348Z",
     "iopub.status.idle": "2021-04-27T04:59:31.202328Z",
     "shell.execute_reply": "2021-04-27T04:59:31.202895Z"
    },
    "papermill": {
     "duration": 15.127238,
     "end_time": "2021-04-27T04:59:31.203128",
     "exception": false,
     "start_time": "2021-04-27T04:59:16.075890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Val Set Error = 0.17\n",
      "Std Val Set Error = 0.024\n",
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "# Convert train.csv to DataFrame\n",
    "pd.set_option('display.max_rows',5)\n",
    "train_data = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "# train_data.head(5)\n",
    "\n",
    "# Define output vector for training data\n",
    "y = train_data['Survived']\n",
    "\n",
    "# Convert test.csv to DataFrame\n",
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "# test_data.head()\n",
    "\n",
    "# Combine test and train data for preprocessing\n",
    "train_shape = train_data.shape\n",
    "train_rows = train_shape[0]\n",
    "data = pd.concat([train_data,test_data],ignore_index=True)\n",
    "\n",
    "# Remove useless columns from input data\n",
    "data.drop(columns = ['PassengerId','Survived'], inplace = True)\n",
    "\n",
    "# Separate column names by numerical/categorical for preprocessing\n",
    "num_features = ['Pclass', 'SibSp', 'Parch', 'Age', 'Fare', 'Ticket']\n",
    "cat_features = ['Embarked','Name','Sex','Cabin']\n",
    "\n",
    "# Extract titles from 'Name' column, and replace values in column\n",
    "def name_transform(X):\n",
    "    names = X['Name']\n",
    "    titles = ['Mr.', 'Mrs.', 'Miss.', 'Master.', 'Don.', 'Dr.', 'Rev.', 'Mme.', 'Ms.', 'Major.', 'Lady.', 'Sir.', 'Mlle.', 'Col.', 'Capt.']\n",
    "    for i in range(len(names)):\n",
    "        for title in titles:\n",
    "            if title in names[i]:\n",
    "                X['Name'][i] = title\n",
    "        if not X['Name'][i] in titles:\n",
    "            X['Name'][i] = 'Other'\n",
    "    return X\n",
    "\n",
    "# Transform 'Ticket' column values into natural log of the ticket number\n",
    "def ticket_transform(X):\n",
    "    tickets = X['Ticket']\n",
    "    for i in range(len(tickets)):\n",
    "        ticket = X['Ticket'][i]\n",
    "        numeric_filter = filter(str.isdigit, ticket)\n",
    "        numeric_string = \"\".join(numeric_filter)\n",
    "        if numeric_string:\n",
    "            X['Ticket'][i] = log(int(float(numeric_string)))\n",
    "        else:\n",
    "            X['Ticket'][i] = 0\n",
    "    return X\n",
    "\n",
    "# Transform 'Cabin' column values into cabin letter\n",
    "def cabin_transform(X):\n",
    "    cabin = X['Cabin']\n",
    "    for i in range(len(cabin)):\n",
    "        cabin = X['Cabin'][i]\n",
    "        alpha_filter = filter(str.isalpha, cabin)\n",
    "        alpha_string = \"\".join(alpha_filter)\n",
    "        if alpha_string:\n",
    "            X['Cabin'][i] = alpha_string\n",
    "        else:\n",
    "            X['Cabin'][i] = 'Other'\n",
    "    return X\n",
    "\n",
    "data = name_transform(data)\n",
    "data = ticket_transform(data)\n",
    "\n",
    "# Fill numerical NaN values with the mode of each column\n",
    "for c in list(train_data[num_features].columns):\n",
    "    data[c].fillna(data[c].mode(dropna=True)[0], inplace = True)\n",
    "# for c in list(data[num_features].columns):\n",
    "#     data[c].fillna(0, inplace = True)\n",
    "\n",
    "# Fill string NaN values with the 'Other'                  \n",
    "for c in list(data[cat_features].columns):\n",
    "    data[c].fillna('Other', inplace = True)\n",
    "\n",
    "data = cabin_transform(data)\n",
    "\n",
    "# Wrapper for one hot encoding of columns in DataFrame\n",
    "def one_hot(X,col_names):\n",
    "    for n in col_names:\n",
    "        col_name = n\n",
    "        # creating instance of labelencoder\n",
    "        labelencoder = LabelEncoder()\n",
    "        # Assigning numerical values and storing in another column\n",
    "        col_cat_name = col_name + 'Cat'\n",
    "        X[col_cat_name] = labelencoder.fit_transform(X[col_name])\n",
    "\n",
    "        # creating instance of one-hot-encoder\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        # passing cat column (label encoded values of col_name)\n",
    "        enc_df = pd.DataFrame(enc.fit_transform(X[[col_name]]).toarray())\n",
    "        enc_df.columns = enc_df.columns.map(str)\n",
    "        # merge with main df, X, on key values\n",
    "        X = X.drop(columns=[col_name, col_cat_name])\n",
    "        X = X.join(enc_df,rsuffix='_' + col_name)\n",
    "    return X\n",
    "\n",
    "data_X = one_hot(data,cat_features)\n",
    "\n",
    "# Separate data back into train and test data DataFrames\n",
    "X = data_X.iloc[:train_rows]\n",
    "X_test = data_X.iloc[train_rows:]\n",
    "\n",
    "# Iterate to cross-validate model performance with randomized test/val set splits\n",
    "errors = []\n",
    "for _ in range(20):\n",
    "    train_X, val_X, train_y, val_y = train_test_split(X, y, train_size = .8)\n",
    "\n",
    "#     print('Train Survival Rate = {}'.format(sum(train_y)/len(train_y)*100))\n",
    "#     print('Val Survival Rate = {}'.format(sum(val_y)/len(val_y)*100))\n",
    "    \n",
    "    # Extreme Gradient Boost Classifier model definition, fitting, and prediction\n",
    "    model = XGBClassifier(n_estimators=3000,max_depth=6,gamma=1,learning_rate=0.001,eval_metric='error',\n",
    "                            subsample=.8,colsample_bytree=.5)\n",
    "    with HiddenPrints():\n",
    "        model.fit(train_X, train_y, eval_set = [(val_X, val_y)],early_stopping_rounds=500)\n",
    "    predicts = model.predict(val_X)\n",
    "\n",
    "    # Plotting error vs. epoch number\n",
    "    results = model.evals_result()\n",
    "\n",
    "    epochs = len(results['validation_0']['error'])\n",
    "    x_axis = range(0, epochs)\n",
    "\n",
    "#     fig, ax = pyplot.subplots()\n",
    "#     ax.plot(x_axis, results['validation_0']['error'], label='Val')\n",
    "#     ax.legend()\n",
    "#     pyplot.ylabel('Error')\n",
    "#     pyplot.title('XGBoost Error')\n",
    "#     pyplot.show()\n",
    "\n",
    "#     print('Val Set Error = {:,.2f}'.format(results['validation_0']['error'][-1]))\n",
    "\n",
    "    errors.append(results['validation_0']['error'][-1])\n",
    "\n",
    "# Compute performance statistics\n",
    "print('Mean Val Set Error = {:,.2f}'.format(sum(errors)/len(errors)))\n",
    "print('Std Val Set Error = {:,.3f}'.format(stdev(errors)))\n",
    "\n",
    "# Predict output for test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Output test data predictions to a .csv file\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('my_submission6.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23.928152,
   "end_time": "2021-04-27T04:59:31.817656",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-27T04:59:07.889504",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
